# Deep-Learning-LAB
# Deep Learning Experiments








A comprehensive collection of deep learning experiments from fundamentals to advanced applications

                     View Experiments â€¢ Setup â€¢ Technologies

ğŸ“‹ Table of Contents

About
Repository Structure
Experiments
Setup & Installation
Technologies Used

ğŸ¯ About

This repository contains hands-on implementations of deep learning concepts, covering everything from basic neural network components to advanced transfer learning techniques.
Each experiment is designed to build practical understanding through implementation and analysis.

ğŸ“ Repository Structure


â”£ ğŸ“‚ Exp_1 Compare TensorFlow, Keras, and PyTorch by implementing linear regression. Analyze code verbosity, API design patterns, and debugging capabilities across frameworks.

â”ƒ â”£ ğŸ““ experiment.ipynb

â”ƒ â”£ ğŸ“‚ datasets

â”ƒ â”— ğŸ“‚ images



â”£ ğŸ“‚ Exp_2 Build neural network components from ground up without high-level libraries. Implement forward propagation, backpropagation, and training mechanisms.

â”ƒ â”£ ğŸ““ experiment.ipynb

â”ƒ â”£ ğŸ“‚ datasets

â”ƒ â”— ğŸ“‚ images



â”£ ğŸ“‚ [Exp_3] End-to-end classification pipeline using deep learning frameworks. Includes data normalization, model building, training curves, and confusion matrix analysis.

â”ƒ â”£ ğŸ““ experiment.ipynb

â”ƒ â”£ ğŸ“‚ datasets

â”ƒ â”— ğŸ“‚ images



â”£ ğŸ“‚ Exp_4 Leverage pretrained models (ResNet, EfficientNet, MobileNet) for image classification. Implement both feature extraction and fine-tuning approaches.

â”ƒ â”£ ğŸ““ experiment.ipynb

â”ƒ â”£ ğŸ“‚ datasets

â”ƒ â”— ğŸ“‚ images



â”£ ğŸ“‚ Exp_5 Deep dive into training mechanisms. Visualize activation functions (Sigmoid, ReLU, Tanh, Softmax) and loss functions. Compare SGD, Momentum, and Adam optimizers.

â”ƒ â”£ ğŸ““ experiment.ipynb

â”ƒ â”£ ğŸ“‚ datasets

â”ƒ â”— ğŸ“‚ images



â”£ ğŸ“‚ Exp_6 Build and train MLP architectures with various configurations. Explore different layer depths, neuron counts, and activation strategies.

â”ƒ â”£ ğŸ““ experiment.ipynb

â”ƒ â”£ ğŸ“‚ datasets

â”ƒ â”— ğŸ“‚ images



â”£ ğŸ“‚ Exp_7 Implement CNN components from scratch. Visualize learned features through feature maps and understand how convolution and pooling operations work.

â”ƒ â”£ ğŸ““ experiment.ipynb

â”ƒ â”£ ğŸ“‚ datasets

â”ƒ â”— ğŸ“‚ images



â”£ ğŸ“‚ Exp_8 Implement CNN with data augmentation strategies to improve model generalization. Apply various image transformations and analyze their impact on classification accuracy.

â”ƒ â”£ ğŸ““ experiment.ipynb

â”ƒ â”£ ğŸ“‚ datasets

â”ƒ â”— ğŸ“‚ images



â”£ ğŸ“‚ Exp_9 Implement CNN-based object detection to identify and localize objects in images. Build detection pipelines with bounding box regression and classification.

â”ƒ â”£ ğŸ““ convolutional-neural-network-cnn-tutorial.ipynb

â”ƒ â”£ ğŸ“‚ test

â”ƒ â”— ğŸ“‚ train



â”£ ğŸ“‚ Exp_10 Introduction to object detection using R-CNN approach. Implement region proposal methods and train detection models on Pascal VOC dataset.

â”ƒ â”£ ğŸ““ Exp10_FasterRCNN_ObjectDetection.ipynb

â”ƒ â”£ ğŸ“‚ Pascal_voc

â”ƒ â”£ ğŸ“„ detection_results.png

â”ƒ â”— ğŸ“„ sample_annotations.png



â”£ ğŸ“‚ Exp_11 Introduction to image segmentation and implement UNet model for pixel-level predictions. Learn encoder-decoder architectures for dense prediction tasks.

â”ƒ â”£ ğŸ““ unet_segmentation.ipynb

â”ƒ â”— ğŸ“„ best_unet_model.pth



â”£ ğŸ“‚ Exp_12 Design standard autoencoder models for image reconstruction and representation learning. Explore latent space representations and dimensionality reduction.

â”ƒ â”£ ğŸ““ Pre_process.ipynb

â”ƒ â”£ ğŸ“„ model.py

â”ƒ â”£ ğŸ“„ autoencoder_celeba.pth

â”ƒ â”£ ğŸ“„ latent_space.png

â”ƒ â”£ ğŸ“„ reconstruction_results.png

â”ƒ â”— ğŸ“„ training_loss.png



â”£ ğŸ“‚ Exp_13 Implement Variational Autoencoders for learning latent distributions and generating novel images. Analyze class-wise latent space representations.

â”ƒ â”£ ğŸ“„ model.py

â”ƒ â”£ ğŸ“„ vae_fashion_mnist.pth

â”ƒ â”£ ğŸ“„ vae_generated_samples.png

â”ƒ â”£ ğŸ“„ vae_interpolation.png

â”ƒ â”£ ğŸ“„ vae_latent_space.png

â”ƒ â”£ ğŸ“„ vae_manifold.png

â”ƒ â”£ ğŸ“„ vae_reconstruction.png

â”ƒ â”— ğŸ“„ vae_training_loss.png



â”£ ğŸ“‚ Exp_14 Develop and train GAN models for creating realistic image samples. Compare generative performance with VAEs in terms of visual fidelity and diversity.

â”ƒ â”— ğŸ“„ model.py

â”— ğŸ“„ README.md


<h1 align="center">Deep Learning Lab</h1>
<p align="center">A comprehensive collection of Deep Learning experiments from basics to advanced applications.</p>

<!-- Table layout (GitHub-safe) -->
<table>
<tr>
<td width="33.5%" valign="top">
  <h3>Experiment 1: Comparative Study of Deep Learning Frameworks</h3>
  <a href="https://github.com/Kritikargv17/DL_LAB_500120185_KRITIKA_RAGHAV/blob/main/Exp1.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <b>Dataset:</b> (use synthetic / iris / any small CSV)
</td>

<td width="33.5%" valign="top">
  <h3>Experiment 2: Building Neural Networks from Scratch</h3>
  <a href="https://github.com/Kritikargv17/DL_LAB_500120185_KRITIKA_RAGHAV/blob/main/Exp2.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/1WUZKaKSo0CeBNe_SCKvAUwW_XzS6QIJs?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>

<td width="33.5%" valign="top">
  <h3>Experiment 3: Classification with DL Frameworks</h3>
  <a href="https://github.com/Kritikargv17/DL_LAB_500120185_KRITIKA_RAGHAV/blob/main/Exp3.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/1PJSrpHZR95mgXz4_flWS3n98qVxMpPtx?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>
</tr>

<tr>
<td width="33%" valign="top">
  <h3>Experiment 4: Transfer Learning for Image Classification</h3>
  <a href="https://github.com/Kritikargv17/DL_LAB_500120185_KRITIKA_RAGHAV/blob/main/Exp4.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/1rD1kYwyt9u_qxmjFCYdbCT3hVCwJKqt4?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>

<td width="33%" valign="top">
  <h3>Experiment 5: Training Deep Networks (Loss, Backprop & Optimization)</h3>
  <a href="https://github.com/Kritikargv17/DL_LAB_500120185_KRITIKA_RAGHAV/blob/main/Exp5.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/1_BzIBlw98-jvg4rrk4yBqYVA6HnubA-x?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>

<td width="33%" valign="top">
  <h3>Experiment 6: Implementation of MLP</h3>
  <a href="https://github.com/Kritikargv17/DL_LAB_500120185_KRITIKA_RAGHAV/blob/main/Exp6.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/1madQFK2jC27xGE7thicgqDTD5w97dy-d?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>
</tr>

<tr>
<td width="33%" valign="top">
  <h3>Experiment 7: Implementing CNN â€” Convolution, Pooling, Feature Maps</h3>
  <a href="https://github.com/Kritikargv17/DL_LAB_500120185_KRITIKA_RAGHAV/blob/main/Exp7.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/1TCT6LMwVNUCvQ3qEK7dFlB3UHfm9sXi6?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>

<td width="33%" valign="top">
  <h3>Experiment 8: CNN with Data Augmentation</h3>
  <a href="https://github.com/Kritikargv17/DL_LAB_500120185_KRITIKA_RAGHAV/blob/main/Exp8.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/140tB6DKKBjv0W31LRhw61UFPYBMrOA-2?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>

<td width="33%" valign="top">
  <h3>Experiment 9: CNN Object Detection</h3>
  <a href="https://github.com/Kritikargv17/DL_LAB_500120185_KRITIKA_RAGHAV/blob/main/Exp9.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/1cTrlI4NDTCUkzbrZ2gJLAOgQUOwAT1Xv?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>
</tr>

<tr>
<td width="33%" valign="top">
  <h3>Experiment 10: Intro to Object Detection (R-CNN)</h3>
  <a href="https://github.com/Kritikargv17/DL_LAB_500120185_KRITIKA_RAGHAV/blob/main/Exp10.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/1ljb-8QJUaKSk8_NjXT92AJ8t1yhr797X?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>

<td width="33%" valign="top">
  <h3>Experiment 11: Image Segmentation with UNet</h3>
  <a href="https://github.com/Kritikargv17/DL_LAB_500120185_KRITIKA_RAGHAV/blob/main/Exp11.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/16jLfsotpTr-BEAbsoSSkEFyUMA_8nJp4?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>

<td width="33%" valign="top">
  <h3>Experiment 12: Autoencoders for Image Reconstruction</h3>
  <a href="https://github.com/Kritikargv17/DL_LAB_500120185_KRITIKA_RAGHAV/blob/main/Exp12.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/1jFbEpBMGBnR6_f09GX_rasLB39pfL9xb?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>
</tr>

<tr>
<td width="33%" valign="top">
  <h3>Experiment 13: Variational Autoencoders (VAEs)</h3>
  <a href="https://github.com/Kritikargv17/DL_LAB_500120185_KRITIKA_RAGHAV/blob/main/Exp13.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/1sK69f_Wp1dHU3R8L6BG-PiaMtE0fsl33?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>

<td width="33%" valign="top">
  <h3>Experiment 14: Generative Adversarial Networks (GANs)</h3>
  <a href="https://github.com/Kritikargv17/DL_LAB_500120185_KRITIKA_RAGHAV/blob/main/Exp14.ipynb"><b>ğŸ”— VIEW EXPERIMENT</b></a><br>
  <a href="https://drive.google.com/drive/folders/1IwShryUGtGadSTJKqYSrm7CASCnius2K?usp=drive_link"><b>ğŸ“ DATASET</b></a>
</td>


</tr>
</table>

# THANKYOU!
Matplotlib	3.x	Data Visualization

Scikit-Learn	1.x	Machine Learning Tools

# Thank You!
